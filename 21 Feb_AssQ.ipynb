{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f856fca-04c1-4b9b-8074-7f2d914b1cc5",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "A1. Web scraping is the process of extracting data from websites automatically using software tools. It involves using a computer program to access web pages and then extract and analyze the data from them.\n",
    "\n",
    "Web scraping is used for several reasons, including:\n",
    "\n",
    "Data Collection: Web scraping is used to collect large amounts of data from websites that are otherwise difficult to obtain. This data can be used for analysis, research, or to build applications.\n",
    "\n",
    "Market Research: Web scraping can be used to gather information about competitors, prices, and market trends. This data can help businesses make better decisions and improve their products and services.\n",
    "\n",
    "Content Aggregation: Web scraping is used to collect content from different websites and combine it into a single location. This is often used for news and content aggregation websites.\n",
    "\n",
    "Three areas where web scraping is commonly used are:\n",
    "\n",
    "E-commerce: Web scraping is used by e-commerce companies to extract product data, prices, and customer reviews from different websites to keep their prices competitive.\n",
    "\n",
    "Research: Researchers use web scraping to gather data from various websites for their research projects.\n",
    "\n",
    "Social Media: Web scraping is used to extract data from social media platforms like Twitter, Instagram, and Facebook to monitor trends and user behavior.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "A2. There are several methods used for web scraping, including:\n",
    "\n",
    "Parsing HTML: This involves using programming languages like Python to extract data from HTML pages. The data is extracted by identifying and parsing the HTML tags and attributes that contain the data.\n",
    "\n",
    "Using APIs: Some websites offer APIs (Application Programming Interfaces) that allow developers to access and extract data in a structured format.\n",
    "\n",
    "Web Scraping Tools: These are specialized tools designed specifically for web scraping, such as Scrapy and Beautiful Soup. These tools automate the process of data extraction and provide features like data cleaning, parsing, and storage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "A3. Beautiful Soup is a Python library used for web scraping purposes. It provides a simple way to navigate and search through the HTML structure of a web page, allowing developers to extract data from it.\n",
    "\n",
    "Beautiful Soup is used because it is easy to learn and use, even for beginners. It also supports different parsing engines, which makes it compatible with different types of HTML and XML documents. Beautiful Soup also provides a wide range of features, such as filtering, searching, and modifying HTML tags, which makes it a versatile tool for web scraping.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "\n",
    "A4. Flask is a web framework for Python that is used to build web applications. It is used in this web scraping project to create a web interface for the data extracted from the web pages.\n",
    "\n",
    "The Flask framework provides a simple way to build web applications, with features like routing, request handling, and template rendering. Flask also integrates well with other Python libraries, such as Beautiful Soup, which is used for web scraping.\n",
    "\n",
    "In this web scraping project, Flask is used to create a simple web interface that displays the data extracted from the web pages. The data is presented in a user-friendly way, making it easy for users to understand and analyze.\n",
    "\n",
    "\n",
    "\n",
    "Q5. Write the names of AWS services used in this project.\n",
    "Code pipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
